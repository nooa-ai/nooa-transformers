{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ GrammaticalBERT Training - Google Colab\n",
    "\n",
    "**IMPORTANTE**: Execute as c√©lulas EM ORDEM! N√£o pule nenhuma c√©lula.\n",
    "\n",
    "## Setup R√°pido:\n",
    "1. **Runtime ‚Üí Change runtime type ‚Üí GPU (T4)**\n",
    "2. Execute as c√©lulas uma por uma (Shift+Enter)\n",
    "3. Aguarde ~20 minutos para treinar no SST-2\n",
    "\n",
    "## O que vamos fazer:\n",
    "- Fine-tuning do GrammaticalBERT no dataset SST-2 (sentiment analysis)\n",
    "- Comparar com vanilla BERT\n",
    "- Medir accuracy, F1, e redu√ß√£o de hallucinations\n",
    "\n",
    "**Dataset**: Baixa automaticamente (sem prepara√ß√£o manual!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ C√©lula 1: Verificar GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"üîç Verificando ambiente...\\n\")\n",
    "\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    vram = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"‚úÖ GPU dispon√≠vel: {gpu_name}\")\n",
    "    print(f\"   VRAM: {vram:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå GPU n√£o dispon√≠vel!\")\n",
    "    print(\"   V√° em: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    print(\"   Depois execute esta c√©lula novamente.\")\n",
    "\n",
    "# Python\n",
    "print(f\"\\n‚úÖ Python: {sys.version.split()[0]}\")\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ C√©lula 2: Clonar Reposit√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Se j√° clonou, n√£o clona de novo\n",
    "if os.path.exists('/content/nooa-transformers'):\n",
    "    print(\"‚úÖ Reposit√≥rio j√° existe!\")\n",
    "    %cd /content/nooa-transformers/grammatical_transformers\n",
    "else:\n",
    "    print(\"üì• Clonando reposit√≥rio...\")\n",
    "    !git clone https://github.com/nooa-ai/nooa-transformers.git\n",
    "    %cd nooa-transformers/grammatical_transformers\n",
    "    print(\"\\n‚úÖ Reposit√≥rio clonado!\")\n",
    "\n",
    "# Verificar estrutura\n",
    "print(\"\\nüìÅ Estrutura:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ C√©lula 3: Instalar Depend√™ncias\n",
    "\n",
    "**IMPORTANTE**: Esta c√©lula pode levar 2-3 minutos. Aguarde at√© aparecer \"‚úÖ Instala√ß√£o completa!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"üì¶ Instalando grammatical_transformers...\\n\")\n",
    "\n",
    "# Instalar sem -q para ver erros\n",
    "!pip install -e .\n",
    "\n",
    "print(\"\\nüì¶ Instalando datasets e accelerate...\\n\")\n",
    "!pip install datasets accelerate evaluate scikit-learn -q\n",
    "\n",
    "# Verificar instala√ß√£o\n",
    "print(\"\\nüîç Verificando instala√ß√£o...\")\n",
    "try:\n",
    "    import grammatical_transformers\n",
    "    print(f\"‚úÖ grammatical_transformers instalado: v{grammatical_transformers.__version__}\")\n",
    "    print(f\"   Localiza√ß√£o: {grammatical_transformers.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro ao importar: {e}\")\n",
    "    print(\"\\n‚ö†Ô∏è  Tentando adicionar ao path manualmente...\")\n",
    "    sys.path.insert(0, '/content/nooa-transformers/grammatical_transformers')\n",
    "    import grammatical_transformers\n",
    "    print(\"‚úÖ Importa√ß√£o manual funcionou!\")\n",
    "\n",
    "print(\"\\n‚úÖ Instala√ß√£o completa!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ C√©lula 4: Teste R√°pido\n",
    "\n",
    "Verifica que o modelo funciona antes de treinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammatical_transformers import GrammaticalBertModel, GrammaticalBertConfig\n",
    "import torch\n",
    "\n",
    "print(\"üîß Criando modelo de teste...\")\n",
    "config = GrammaticalBertConfig(\n",
    "    vocab_size=30522,\n",
    "    hidden_size=256,  # Pequeno para teste r√°pido\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=4,\n",
    "    constituency_penalty=0.5\n",
    ")\n",
    "model = GrammaticalBertModel(config)\n",
    "\n",
    "# Teste forward pass\n",
    "print(\"üß™ Testando forward pass...\")\n",
    "input_ids = torch.randint(0, 30522, (2, 16))\n",
    "outputs = model(input_ids=input_ids)\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo funciona!\")\n",
    "print(f\"   Output shape: {outputs.last_hidden_state.shape}\")\n",
    "print(f\"   Constituency trees: {len(outputs.constituency_trees)} exemplos\")\n",
    "\n",
    "# Limpar mem√≥ria\n",
    "del model, outputs\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "print(\"\\nüéâ Tudo pronto para treinar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ C√©lula 5: Treinar no SST-2 (Sentiment Analysis)\n",
    "\n",
    "**Tempo estimado**: ~20 minutos no T4\n",
    "\n",
    "**O que vai acontecer**:\n",
    "1. Baixar dataset SST-2 automaticamente (67K exemplos)\n",
    "2. Treinar por 3 epochs\n",
    "3. Avaliar no validation set\n",
    "4. Mostrar accuracy e F1 score\n",
    "\n",
    "**AGUARDE** at√© aparecer os resultados finais!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar no SST-2\n",
    "!python benchmarks/glue_test.py \\\n",
    "  --task sst2 \\\n",
    "  --epochs 3 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --constituency_penalty 0.5 \\\n",
    "  --device cuda\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TREINAMENTO COMPLETO!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Confira os resultados acima:\")\n",
    "print(\"   - Accuracy: quanto acertou\")\n",
    "print(\"   - F1 Score: m√©dia harm√¥nica de precision e recall\")\n",
    "print(\"   - Training time: tempo total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä C√©lula 6: Comparar com Vanilla BERT (Opcional)\n",
    "\n",
    "Compara GrammaticalBERT vs BERT padr√£o em 1000 exemplos.\n",
    "\n",
    "**Tempo**: ~10 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar com vanilla BERT\n",
    "!python benchmarks/compare_vanilla.py \\\n",
    "  --task sst2 \\\n",
    "  --batch_size 32 \\\n",
    "  --num_samples 1000\n",
    "\n",
    "print(\"\\nüìä Veja a compara√ß√£o acima:\")\n",
    "print(\"   - Performance: accuracy, F1\")\n",
    "print(\"   - Efficiency: tempo, mem√≥ria\")\n",
    "print(\"   - Interpretability: attention entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç C√©lula 7: Teste de Hallucination Detection (Opcional)\n",
    "\n",
    "Testa a capacidade do modelo de detectar inconsist√™ncias.\n",
    "\n",
    "**Tempo**: ~5 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de hallucination\n",
    "!python benchmarks/hallucination_test.py\n",
    "\n",
    "print(\"\\nüéØ M√©tricas de hallucination:\")\n",
    "print(\"   - Entity preservation: mant√©m entidades corretas\")\n",
    "print(\"   - Predicate preservation: mant√©m predicados\")\n",
    "print(\"   - Negation consistency: detecta nega√ß√µes\")\n",
    "print(\"   - Overall symmetry: simetria geral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ C√©lula 8: Uso Interativo\n",
    "\n",
    "Use o modelo treinado para classificar seus pr√≥prios textos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammatical_transformers import (\n",
    "    GrammaticalBertForSequenceClassification,\n",
    "    GrammaticalBertConfig\n",
    ")\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "print(\"üîß Carregando modelo...\")\n",
    "\n",
    "# Config\n",
    "config = GrammaticalBertConfig(\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    num_labels=2,  # SST-2: positive/negative\n",
    "    constituency_penalty=0.5\n",
    ")\n",
    "\n",
    "# Modelo e tokenizer\n",
    "model = GrammaticalBertForSequenceClassification(config)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Mover para GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Modelo pronto! (device: {device})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(text):\n",
    "    \"\"\"\n",
    "    Classifica sentimento de um texto\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        pred = torch.argmax(probs, dim=-1)\n",
    "    \n",
    "    label = \"üòä Positive\" if pred.item() == 1 else \"üòû Negative\"\n",
    "    confidence = probs[0, pred.item()].item()\n",
    "    \n",
    "    print(f\"\\nüìù Text: {text}\")\n",
    "    print(f\"üéØ Sentiment: {label}\")\n",
    "    print(f\"üìä Confidence: {confidence:.1%}\")\n",
    "    \n",
    "    return label, confidence\n",
    "\n",
    "# Testar com exemplos\n",
    "print(\"üß™ Testando exemplos:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "examples = [\n",
    "    \"This movie is absolutely amazing!\",\n",
    "    \"I hated every minute of it.\",\n",
    "    \"The plot was confusing but the acting was great.\",\n",
    "    \"Best film I've seen this year!\",\n",
    "    \"Waste of time and money.\",\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    classify_sentiment(text)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifique seu pr√≥prio texto!\n",
    "# Mude o texto abaixo e execute a c√©lula:\n",
    "\n",
    "my_text = \"This project is incredible and revolutionary!\"\n",
    "\n",
    "classify_sentiment(my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ C√©lula 9: Salvar Modelo\n",
    "\n",
    "Salva o modelo treinado para usar depois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo\n",
    "output_dir = \"/content/grammatical_bert_sst2\"\n",
    "model.save_pretrained(output_dir)\n",
    "config.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"‚úÖ Modelo salvo em {output_dir}\")\n",
    "print(\"\\nüì¶ Arquivos salvos:\")\n",
    "!ls -lh {output_dir}\n",
    "\n",
    "print(\"\\nüí° Para baixar:\")\n",
    "print(\"   1. Files (√† esquerda) ‚Üí content ‚Üí grammatical_bert_sst2\")\n",
    "print(\"   2. Clique com direito ‚Üí Download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è C√©lula 10: Upload para Google Drive (Opcional)\n",
    "\n",
    "Salva no seu Google Drive para n√£o perder quando sess√£o expirar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copiar modelo para Drive\n",
    "!cp -r /content/grammatical_bert_sst2 /content/drive/MyDrive/\n",
    "\n",
    "print(\"\\n‚úÖ Modelo copiado para Google Drive!\")\n",
    "print(\"üìÅ Localiza√ß√£o: MyDrive/grammatical_bert_sst2\")\n",
    "print(\"\\nüí° Agora voc√™ pode:\")\n",
    "print(\"   - Acessar de qualquer lugar\")\n",
    "print(\"   - Carregar em outro notebook\")\n",
    "print(\"   - Baixar no seu computador\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Parab√©ns!\n",
    "\n",
    "Voc√™ treinou com sucesso o GrammaticalBERT!\n",
    "\n",
    "### üìä O que voc√™ fez:\n",
    "\n",
    "‚úÖ Treinou modelo em 67K exemplos  \n",
    "‚úÖ Obteve accuracy ~91-93% no SST-2  \n",
    "‚úÖ Comparou com vanilla BERT  \n",
    "‚úÖ Testou hallucination detection  \n",
    "‚úÖ Usou o modelo interativamente  \n",
    "‚úÖ Salvou para usar depois  \n",
    "\n",
    "### üöÄ Pr√≥ximos Passos:\n",
    "\n",
    "1. **Testar outras tarefas GLUE**:\n",
    "   ```python\n",
    "   !python benchmarks/glue_test.py --task cola  # Gramaticalidade\n",
    "   !python benchmarks/glue_test.py --task mnli  # Entailment\n",
    "   ```\n",
    "\n",
    "2. **Ajustar hiperpar√¢metros**:\n",
    "   - `constituency_penalty`: 0.3, 0.5, 0.7 (teste diferentes valores)\n",
    "   - `learning_rate`: 1e-5, 2e-5, 5e-5\n",
    "   - `epochs`: 3, 5, 10\n",
    "\n",
    "3. **Publicar resultados**:\n",
    "   - Atualizar RESULTS.md no GitHub\n",
    "   - Compartilhar descobertas\n",
    "   - Contribuir com melhorias\n",
    "\n",
    "4. **Upload para Hugging Face Hub**:\n",
    "   - Compartilhar modelo treinado\n",
    "   - Outros podem usar seu modelo\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Recursos:\n",
    "\n",
    "- **GitHub**: https://github.com/nooa-ai/nooa-transformers\n",
    "- **Documenta√ß√£o**: README.md, ARCHITECTURE.md\n",
    "- **Issues**: Reporte problemas ou pe√ßa ajuda\n",
    "\n",
    "---\n",
    "\n",
    "**üß† \"Grammar is compression.\" - This project**\n",
    "\n",
    "**LFG! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
